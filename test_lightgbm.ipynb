{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['CFLAGS'] = '-fopenmp'\n",
    "os.environ['LDFLAGS'] = '-fopenmp'\n",
    "\n",
    "os.environ[\"C_INCLUDE_PATH\"] = np.get_include()\n",
    "\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "\n",
    "from rocauc_pairwise.sigmoid_pairwise_auc_cpu import sigmoid_pairwise_diff_hess_auc_cpu, sigmoid_pairwise_diff_hess_auc_exact_cpu\n",
    "from rocauc_pairwise.sigmoid_pairwise_cpu import sigmoid_pairwise_diff_hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm\n",
    "from lightgbm import LGBMClassifier, Dataset\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.read_csv('./data/breast-cancer.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['class'] = X.diagnosis.apply(lambda x: int(x == 'M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop('diagnosis', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelencoder=OrdinalEncoder()\n",
    "#X[X.columns] = labelencoder.fit_transform(X[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./data/orange_small_churn_train_data.csv', index_col='ID')\n",
    "\n",
    "non_cat_features = [f'Var{i + 1}' for i in range(190)]\n",
    "cat_features = [f'Var{k + 1}' for k in range(190, 190 + 40)]\n",
    "\n",
    "mask = X[cat_features].nunique() < 50\n",
    "\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "X[cat_features] = oe.fit_transform(X[cat_features])\n",
    "\n",
    "X['labels'] += 1\n",
    "X['labels'] /= 2\n",
    "\n",
    "X = X.drop(18298, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.sample(5_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.drop('labels', axis=1), X['labels'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = Dataset(X_train, y_train, free_raw_data=True)\n",
    "val = Dataset(X_test, y_test, free_raw_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_lgbm(preds, train_data):\n",
    "    y = train_data.get_label()\n",
    "    auc = roc_auc_score(y, preds)\n",
    "    is_higher_better = True\n",
    "    return 'default_rate', auc, is_higher_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/envs/rocauc_envs/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/dmitry/anaconda3/envs/rocauc_envs/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1110, number of negative: 13528\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12878\n",
      "[LightGBM] [Info] Number of data points in the train set: 14638, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.075830 -> initscore=-2.500402\n",
      "[LightGBM] [Info] Start training from score -2.500402\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[50]\tfit's binary_logloss: 0.26223\tfit's default_rate: 0.768806\tval's binary_logloss: 0.258469\tval's default_rate: 0.688975\n",
      "[100]\tfit's binary_logloss: 0.257008\tfit's default_rate: 0.77475\tval's binary_logloss: 0.256418\tval's default_rate: 0.69023\n",
      "[150]\tfit's binary_logloss: 0.252433\tfit's default_rate: 0.781188\tval's binary_logloss: 0.254539\tval's default_rate: 0.6938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[150]\tfit's binary_logloss: 0.252433\tfit's default_rate: 0.781188\tval's binary_logloss: 0.254539\tval's default_rate: 0.6938\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.train(\n",
    "    params={'learning_rate': 0.001,\n",
    "            'num_leaves' : 58,\n",
    "            'objective': 'binary'},\n",
    "    train_set=fit,\n",
    "    num_boost_round=150,\n",
    "    valid_sets=(fit, val),\n",
    "    valid_names=('fit', 'val'),\n",
    "    early_stopping_rounds=150,\n",
    "    verbose_eval=50,\n",
    "    feval=roc_auc_lgbm\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_pairwise_loss(preds, train_data):\n",
    "    y = train_data.get_label()\n",
    "    \n",
    "    y = np.array(y, dtype=np.int64)\n",
    "    preds = np.array(preds, dtype=np.float64)\n",
    "\n",
    "    if np.mean(preds) == 0:\n",
    "        preds[0] = 1.0\n",
    "\n",
    "\n",
    "    grad, hess = sigmoid_pairwise_diff_hess_auc_exact_cpu(y, np.exp(preds), 12)\n",
    "    \n",
    "    return -grad, -hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/envs/rocauc_envs/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12878\n",
      "[LightGBM] [Info] Number of data points in the train set: 14638, number of used features: 212\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tfit's default_rate: 0.498099\tval's default_rate: 0.504432\n",
      "[2]\tfit's default_rate: 0.673246\tval's default_rate: 0.656408\n",
      "[3]\tfit's default_rate: 0.731487\tval's default_rate: 0.682645\n",
      "[4]\tfit's default_rate: 0.741912\tval's default_rate: 0.68541\n",
      "[5]\tfit's default_rate: 0.745968\tval's default_rate: 0.686886\n",
      "[6]\tfit's default_rate: 0.748238\tval's default_rate: 0.688966\n",
      "[7]\tfit's default_rate: 0.749889\tval's default_rate: 0.689596\n",
      "[8]\tfit's default_rate: 0.750363\tval's default_rate: 0.689258\n",
      "[9]\tfit's default_rate: 0.751441\tval's default_rate: 0.689248\n",
      "[10]\tfit's default_rate: 0.751225\tval's default_rate: 0.69063\n",
      "[11]\tfit's default_rate: 0.750721\tval's default_rate: 0.690986\n",
      "[12]\tfit's default_rate: 0.750678\tval's default_rate: 0.690995\n",
      "[13]\tfit's default_rate: 0.75103\tval's default_rate: 0.691867\n",
      "[14]\tfit's default_rate: 0.751324\tval's default_rate: 0.69255\n",
      "[15]\tfit's default_rate: 0.751137\tval's default_rate: 0.693273\n",
      "[16]\tfit's default_rate: 0.751397\tval's default_rate: 0.693598\n",
      "[17]\tfit's default_rate: 0.751892\tval's default_rate: 0.693343\n",
      "[18]\tfit's default_rate: 0.755373\tval's default_rate: 0.693444\n",
      "[19]\tfit's default_rate: 0.7557\tval's default_rate: 0.693738\n",
      "[20]\tfit's default_rate: 0.755451\tval's default_rate: 0.694\n",
      "[21]\tfit's default_rate: 0.755416\tval's default_rate: 0.69405\n",
      "[22]\tfit's default_rate: 0.75548\tval's default_rate: 0.693931\n",
      "[23]\tfit's default_rate: 0.754881\tval's default_rate: 0.694125\n",
      "[24]\tfit's default_rate: 0.757562\tval's default_rate: 0.694154\n",
      "[25]\tfit's default_rate: 0.75751\tval's default_rate: 0.693842\n",
      "[26]\tfit's default_rate: 0.756927\tval's default_rate: 0.693622\n",
      "[27]\tfit's default_rate: 0.757026\tval's default_rate: 0.694276\n",
      "[28]\tfit's default_rate: 0.757259\tval's default_rate: 0.694491\n",
      "[29]\tfit's default_rate: 0.756995\tval's default_rate: 0.694544\n",
      "[30]\tfit's default_rate: 0.756927\tval's default_rate: 0.69524\n",
      "[31]\tfit's default_rate: 0.757246\tval's default_rate: 0.694857\n",
      "[32]\tfit's default_rate: 0.757208\tval's default_rate: 0.694562\n",
      "[33]\tfit's default_rate: 0.757185\tval's default_rate: 0.694823\n",
      "[34]\tfit's default_rate: 0.757328\tval's default_rate: 0.695406\n",
      "[35]\tfit's default_rate: 0.75782\tval's default_rate: 0.694997\n",
      "[36]\tfit's default_rate: 0.757755\tval's default_rate: 0.695044\n",
      "[37]\tfit's default_rate: 0.757668\tval's default_rate: 0.694925\n",
      "[38]\tfit's default_rate: 0.75745\tval's default_rate: 0.694964\n",
      "[39]\tfit's default_rate: 0.757439\tval's default_rate: 0.695002\n",
      "[40]\tfit's default_rate: 0.757382\tval's default_rate: 0.694965\n",
      "[41]\tfit's default_rate: 0.757313\tval's default_rate: 0.695157\n",
      "[42]\tfit's default_rate: 0.756923\tval's default_rate: 0.695325\n",
      "[43]\tfit's default_rate: 0.757167\tval's default_rate: 0.69498\n",
      "[44]\tfit's default_rate: 0.757102\tval's default_rate: 0.694662\n",
      "[45]\tfit's default_rate: 0.757028\tval's default_rate: 0.694877\n",
      "[46]\tfit's default_rate: 0.757052\tval's default_rate: 0.69436\n",
      "[47]\tfit's default_rate: 0.756539\tval's default_rate: 0.69435\n",
      "[48]\tfit's default_rate: 0.756478\tval's default_rate: 0.694523\n",
      "[49]\tfit's default_rate: 0.756373\tval's default_rate: 0.694503\n",
      "[50]\tfit's default_rate: 0.756257\tval's default_rate: 0.694696\n",
      "[51]\tfit's default_rate: 0.756164\tval's default_rate: 0.694629\n",
      "[52]\tfit's default_rate: 0.755871\tval's default_rate: 0.694678\n",
      "[53]\tfit's default_rate: 0.755536\tval's default_rate: 0.694709\n",
      "[54]\tfit's default_rate: 0.755147\tval's default_rate: 0.694755\n",
      "[55]\tfit's default_rate: 0.755095\tval's default_rate: 0.694754\n",
      "[56]\tfit's default_rate: 0.75508\tval's default_rate: 0.694722\n",
      "[57]\tfit's default_rate: 0.755036\tval's default_rate: 0.694698\n",
      "[58]\tfit's default_rate: 0.755048\tval's default_rate: 0.694711\n",
      "[59]\tfit's default_rate: 0.755135\tval's default_rate: 0.694555\n",
      "[60]\tfit's default_rate: 0.755039\tval's default_rate: 0.694595\n",
      "[61]\tfit's default_rate: 0.754975\tval's default_rate: 0.694675\n",
      "[62]\tfit's default_rate: 0.754917\tval's default_rate: 0.694972\n",
      "[63]\tfit's default_rate: 0.754959\tval's default_rate: 0.694989\n",
      "[64]\tfit's default_rate: 0.755154\tval's default_rate: 0.694681\n",
      "[65]\tfit's default_rate: 0.755125\tval's default_rate: 0.694659\n",
      "[66]\tfit's default_rate: 0.755125\tval's default_rate: 0.694699\n",
      "[67]\tfit's default_rate: 0.755092\tval's default_rate: 0.694696\n",
      "[68]\tfit's default_rate: 0.755066\tval's default_rate: 0.694722\n",
      "[69]\tfit's default_rate: 0.755066\tval's default_rate: 0.694737\n",
      "[70]\tfit's default_rate: 0.755071\tval's default_rate: 0.694741\n",
      "[71]\tfit's default_rate: 0.75506\tval's default_rate: 0.694625\n",
      "[72]\tfit's default_rate: 0.755038\tval's default_rate: 0.694621\n",
      "[73]\tfit's default_rate: 0.755035\tval's default_rate: 0.694633\n",
      "[74]\tfit's default_rate: 0.754993\tval's default_rate: 0.694487\n",
      "[75]\tfit's default_rate: 0.754978\tval's default_rate: 0.69447\n",
      "[76]\tfit's default_rate: 0.754946\tval's default_rate: 0.694435\n",
      "[77]\tfit's default_rate: 0.754969\tval's default_rate: 0.694444\n",
      "[78]\tfit's default_rate: 0.754911\tval's default_rate: 0.694439\n",
      "[79]\tfit's default_rate: 0.754867\tval's default_rate: 0.694443\n",
      "[80]\tfit's default_rate: 0.754854\tval's default_rate: 0.694431\n",
      "[81]\tfit's default_rate: 0.754841\tval's default_rate: 0.694425\n",
      "[82]\tfit's default_rate: 0.754835\tval's default_rate: 0.694421\n",
      "[83]\tfit's default_rate: 0.754813\tval's default_rate: 0.694424\n",
      "[84]\tfit's default_rate: 0.754691\tval's default_rate: 0.694393\n",
      "[85]\tfit's default_rate: 0.754789\tval's default_rate: 0.694332\n",
      "[86]\tfit's default_rate: 0.754774\tval's default_rate: 0.694343\n",
      "[87]\tfit's default_rate: 0.754775\tval's default_rate: 0.694361\n",
      "[88]\tfit's default_rate: 0.754773\tval's default_rate: 0.694369\n",
      "[89]\tfit's default_rate: 0.754689\tval's default_rate: 0.694369\n",
      "[90]\tfit's default_rate: 0.754627\tval's default_rate: 0.694332\n",
      "[91]\tfit's default_rate: 0.754684\tval's default_rate: 0.694323\n",
      "[92]\tfit's default_rate: 0.754686\tval's default_rate: 0.694298\n",
      "[93]\tfit's default_rate: 0.754627\tval's default_rate: 0.694243\n",
      "[94]\tfit's default_rate: 0.754591\tval's default_rate: 0.694227\n",
      "[95]\tfit's default_rate: 0.75458\tval's default_rate: 0.694215\n",
      "[96]\tfit's default_rate: 0.75459\tval's default_rate: 0.694183\n",
      "[97]\tfit's default_rate: 0.75451\tval's default_rate: 0.694166\n",
      "[98]\tfit's default_rate: 0.754814\tval's default_rate: 0.694026\n",
      "[99]\tfit's default_rate: 0.754734\tval's default_rate: 0.694138\n",
      "[100]\tfit's default_rate: 0.754712\tval's default_rate: 0.694137\n",
      "[101]\tfit's default_rate: 0.754665\tval's default_rate: 0.694121\n",
      "[102]\tfit's default_rate: 0.754621\tval's default_rate: 0.694047\n",
      "[103]\tfit's default_rate: 0.75461\tval's default_rate: 0.694026\n",
      "[104]\tfit's default_rate: 0.754716\tval's default_rate: 0.694024\n",
      "[105]\tfit's default_rate: 0.754718\tval's default_rate: 0.69403\n",
      "[106]\tfit's default_rate: 0.754713\tval's default_rate: 0.69402\n",
      "[107]\tfit's default_rate: 0.754697\tval's default_rate: 0.693837\n",
      "[108]\tfit's default_rate: 0.754699\tval's default_rate: 0.694057\n",
      "[109]\tfit's default_rate: 0.754699\tval's default_rate: 0.694081\n",
      "[110]\tfit's default_rate: 0.754639\tval's default_rate: 0.694039\n",
      "[111]\tfit's default_rate: 0.754638\tval's default_rate: 0.694037\n",
      "[112]\tfit's default_rate: 0.754582\tval's default_rate: 0.693932\n",
      "[113]\tfit's default_rate: 0.754579\tval's default_rate: 0.693943\n",
      "[114]\tfit's default_rate: 0.754563\tval's default_rate: 0.693954\n",
      "[115]\tfit's default_rate: 0.75455\tval's default_rate: 0.693931\n",
      "[116]\tfit's default_rate: 0.754547\tval's default_rate: 0.693921\n",
      "[117]\tfit's default_rate: 0.75453\tval's default_rate: 0.693902\n",
      "[118]\tfit's default_rate: 0.754456\tval's default_rate: 0.694072\n",
      "[119]\tfit's default_rate: 0.754435\tval's default_rate: 0.694055\n",
      "[120]\tfit's default_rate: 0.754429\tval's default_rate: 0.694027\n",
      "[121]\tfit's default_rate: 0.754441\tval's default_rate: 0.694164\n",
      "[122]\tfit's default_rate: 0.754346\tval's default_rate: 0.694188\n",
      "[123]\tfit's default_rate: 0.754321\tval's default_rate: 0.694149\n",
      "[124]\tfit's default_rate: 0.754416\tval's default_rate: 0.694146\n",
      "[125]\tfit's default_rate: 0.754419\tval's default_rate: 0.694152\n",
      "[126]\tfit's default_rate: 0.754439\tval's default_rate: 0.694178\n",
      "[127]\tfit's default_rate: 0.754473\tval's default_rate: 0.694068\n",
      "[128]\tfit's default_rate: 0.754486\tval's default_rate: 0.694077\n",
      "[129]\tfit's default_rate: 0.754492\tval's default_rate: 0.694088\n",
      "[130]\tfit's default_rate: 0.754496\tval's default_rate: 0.694059\n",
      "[131]\tfit's default_rate: 0.754397\tval's default_rate: 0.694241\n",
      "[132]\tfit's default_rate: 0.754489\tval's default_rate: 0.694202\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.train(\n",
    "        params={'learning_rate': 0.01,\n",
    "                'num_leaves' : 31,\n",
    "                    'boosting_type' : 'gbdt'},\n",
    "        train_set=fit,\n",
    "        num_boost_round=800,\n",
    "        valid_sets=(fit, val),\n",
    "        valid_names=('fit', 'val'),\n",
    "        feval=roc_auc_lgbm,\n",
    "        verbose_eval=1,\n",
    "        fobj =sigmoid_pairwise_loss\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(0, 2, 1000)\n",
    "y_pred = np.zeros(1000)\n",
    "y_pred = np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_pairwise_diff_hess_auc_exact_cpu(y_true, y_pred, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocauc_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
